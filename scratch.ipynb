{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scod\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST, KMNIST, EMNIST\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scripts.train_functions import create_dataloaders, main, set_up_model, load_ckp\n",
    "from scripts.benchmark_functions import alg_flags, scod_flagger, ds_scod_flagger, create_scod_model, create_benchmark_seq_batches, get_Lt_J\n",
    "from scripts.utils import eval_scod, init_scod\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take a mixed batch (x% fashion, y% kmnist, z% test)\\\n",
    "Flag OOD f% using scod k-highest/ds-scod\n",
    "\n",
    "2. Continual training: \\\n",
    "    a. Baseline method: mix new with old training\\\n",
    "    b. Our method: use EWC to prevent forgetting\\\n",
    "    Train for N epochs on mixture\n",
    "\n",
    "3. Plot loss evolution on \\\n",
    "    a. Mixture\\\n",
    "    b. Just validation set (in distribution)\\\n",
    "    c. FashionMNIST (OOD 1)\\\n",
    "    d. KMNIST (OOD 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"~/data/\"\n",
    "batch_size = 100\n",
    "dataset_name = \"mnist\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnist_train': <torch.utils.data.dataloader.DataLoader object at 0x7f82f2fbd8d0>, 'mnist_test': <torch.utils.data.dataloader.DataLoader object at 0x7f82f2fbdb50>, 'fashion': <torch.utils.data.dataloader.DataLoader object at 0x7f82f2fbdb90>, 'kmnist': <torch.utils.data.dataloader.DataLoader object at 0x7f82f2fbda90>, 'emnist': <torch.utils.data.dataloader.DataLoader object at 0x7f82f2fbdad0>}\n"
     ]
    }
   ],
   "source": [
    "dataloaders, dataset_sizes = create_dataloaders(root, batch_size, dataset_name=dataset_name)\n",
    "\n",
    "print(dataloaders)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add SCOD wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight space dimension: 4.443e+04\n",
      "computing basis\n",
      "using T = 304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbcb2c822ea4be9b605d77c62f1532f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model_path = \"./best_model/mnist/best_model.pt\"\n",
    "\n",
    "unc_model = create_scod_model(load_model_path, dataset_name, batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mixture dataset using flagged inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test seq  0  algorithm  0  flagged:  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, True, True, False, True, True, True]\n",
      "Test seq  1  algorithm  0  flagged:  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, True, True, True, False, True, True, True, False, True]\n",
      "Test seq  2  algorithm  0  flagged:  [False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, True, True, True, True, True, False]\n",
      "Test seq  3  algorithm  0  flagged:  [False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, False, True, True, True, True, True]\n",
      "Test seq  4  algorithm  0  flagged:  [False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, True, False, True, True, True, True]\n",
      "Added  mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0  to list of dataloaders.\n",
      "Added  mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1  to list of dataloaders.\n",
      "Added  mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2  to list of dataloaders.\n",
      "Added  mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3  to list of dataloaders.\n",
      "Added  mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4  to list of dataloaders.\n"
     ]
    }
   ],
   "source": [
    "ood_ratio = 0.1\n",
    "mix_train_ratio = 1.0\n",
    "num_batches = 5\n",
    "\n",
    "ood_num = int(batch_size*ood_ratio)\n",
    "mix_train_num = int(batch_size*mix_train_ratio)\n",
    "\n",
    "batch_compositions = [  {'mnist_test':batch_size - ood_num,'fashion':ood_num}]*num_batches\n",
    "train_batch_compositions = [{'mnist_train':mix_train_num}]*num_batches\n",
    "\n",
    "flag_limit = ood_num\n",
    "# algs_to_test = [lambda x: scod_flagger(x, unc_model, flag_limit=flag_limit, debug = False, dist_layer = scod.distributions.CategoricalLogitLayer()), \n",
    "#                 lambda x: ds_scod_flagger(x, unc_model, flag_limit=flag_limit, dist_layer = scod.distributions.CategoricalLogitLayer())]\n",
    "algs_to_test = [lambda x: scod_flagger(x, unc_model, flag_limit=flag_limit, debug = False, dist_layer = scod.distributions.CategoricalLogitLayer())]\n",
    "algs_names = ['scod_flagged']\n",
    "\n",
    "flagged_inputs, flagged_labels, flagged_fnames, flags = alg_flags(algs_to_test, dataset_name, batch_size, num_batches, batch_compositions)\n",
    "train_inputs, train_labels, train_fnames = create_benchmark_seq_batches(dataset_name, mix_train_num, num_batches, train_batch_compositions)\n",
    "for k in range(len(algs_to_test)):\n",
    "    for i in range(num_batches):\n",
    "        flagged_subset = [(ts, lbl) for (ts,lbl,flg) in zip(flagged_inputs[i], flagged_labels[i], flags[i][k]) if flg]\n",
    "        train_subset = [(ts, lbl) for (ts,lbl) in zip(train_inputs[i], train_labels[i])]\n",
    "        refine_subset = flagged_subset + train_subset\n",
    "        random.shuffle(refine_subset)\n",
    "\n",
    "        mix_name = \"mixture_\"+str(batch_compositions[i])+'_'+algs_names[k]+'_'+str(len(flagged_subset))+'_train_'+str(len(train_subset))+\"_batch_\"+str(i)\n",
    "        \n",
    "        dataloaders[mix_name] = DataLoader(refine_subset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        dataset_sizes[mix_name]  = len(refine_subset)\n",
    "        print(\"Added \", mix_name, \" to list of dataloaders.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_epoch_idx =  17\n",
      "valid_loss = 0.042841\n",
      "Epoch 18/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3604\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9732\n",
      "val kmnist Loss: 8.6087\n",
      "Epoch 19/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3594\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9610\n",
      "val kmnist Loss: 8.6038\n",
      "Epoch 20/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3579\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9450\n",
      "val kmnist Loss: 8.5974\n",
      "Epoch 21/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3558\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9226\n",
      "val kmnist Loss: 8.5884\n",
      "Epoch 22/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3528\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8867\n",
      "val kmnist Loss: 8.5751\n",
      "Epoch 23/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3486\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8430\n",
      "val kmnist Loss: 8.5598\n",
      "Epoch 24/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3419\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8007\n",
      "val kmnist Loss: 8.5451\n",
      "Epoch 25/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3362\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7959\n",
      "val kmnist Loss: 8.5435\n",
      "Epoch 26/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3355\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7907\n",
      "val kmnist Loss: 8.5417\n",
      "Epoch 27/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3348\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7858\n",
      "val kmnist Loss: 8.5401\n",
      "Epoch 28/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3339\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7805\n",
      "val kmnist Loss: 8.5382\n",
      "Epoch 29/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3333\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7750\n",
      "val kmnist Loss: 8.5362\n",
      "Epoch 30/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3324\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7702\n",
      "val kmnist Loss: 8.5344\n",
      "Epoch 31/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3317\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7657\n",
      "val kmnist Loss: 8.5328\n",
      "Epoch 32/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_0 Loss: 0.3311\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7652\n",
      "val kmnist Loss: 8.5326\n",
      "start_epoch_idx =  17\n",
      "valid_loss = 0.042841\n",
      "Epoch 18/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.3298\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9571\n",
      "val kmnist Loss: 8.6017\n",
      "Epoch 19/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.3262\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9143\n",
      "val kmnist Loss: 8.5835\n",
      "Epoch 20/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.3194\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8726\n",
      "val kmnist Loss: 8.5659\n",
      "Epoch 21/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.3116\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8229\n",
      "val kmnist Loss: 8.5445\n",
      "Epoch 22/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.3032\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7613\n",
      "val kmnist Loss: 8.5183\n",
      "Epoch 23/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2942\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.7006\n",
      "val kmnist Loss: 8.4930\n",
      "Epoch 24/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2843\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.6468\n",
      "val kmnist Loss: 8.4703\n",
      "Epoch 25/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2760\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6417\n",
      "val kmnist Loss: 8.4681\n",
      "Epoch 26/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2753\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6362\n",
      "val kmnist Loss: 8.4657\n",
      "Epoch 27/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2744\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6291\n",
      "val kmnist Loss: 8.4627\n",
      "Epoch 28/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2737\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6213\n",
      "val kmnist Loss: 8.4593\n",
      "Epoch 29/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2727\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6144\n",
      "val kmnist Loss: 8.4563\n",
      "Epoch 30/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2718\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6081\n",
      "val kmnist Loss: 8.4535\n",
      "Epoch 31/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2710\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6022\n",
      "val kmnist Loss: 8.4509\n",
      "Epoch 32/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_1 Loss: 0.2701\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.6017\n",
      "val kmnist Loss: 8.4507\n",
      "start_epoch_idx =  17\n",
      "valid_loss = 0.042841\n",
      "Epoch 18/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3867\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9655\n",
      "val kmnist Loss: 8.6045\n",
      "Epoch 19/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3828\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9272\n",
      "val kmnist Loss: 8.5869\n",
      "Epoch 20/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3749\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8730\n",
      "val kmnist Loss: 8.5624\n",
      "Epoch 21/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3609\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8090\n",
      "val kmnist Loss: 8.5339\n",
      "Epoch 22/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3477\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.7358\n",
      "val kmnist Loss: 8.5012\n",
      "Epoch 23/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3300\n",
      "val mnist_test Loss: 0.0429\n",
      "val fashion Loss: 5.6673\n",
      "val kmnist Loss: 8.4696\n",
      "Epoch 24/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.3143\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.6034\n",
      "val kmnist Loss: 8.4393\n",
      "Epoch 25/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2994\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.5975\n",
      "val kmnist Loss: 8.4365\n",
      "Epoch 26/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2980\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.5918\n",
      "val kmnist Loss: 8.4338\n",
      "Epoch 27/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2965\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.5856\n",
      "val kmnist Loss: 8.4308\n",
      "Epoch 28/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2952\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.5791\n",
      "val kmnist Loss: 8.4278\n",
      "Epoch 29/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2936\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.5729\n",
      "val kmnist Loss: 8.4249\n",
      "Epoch 30/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2920\n",
      "val mnist_test Loss: 0.0430\n",
      "val fashion Loss: 5.5664\n",
      "val kmnist Loss: 8.4218\n",
      "Epoch 31/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2906\n",
      "val mnist_test Loss: 0.0431\n",
      "val fashion Loss: 5.5596\n",
      "val kmnist Loss: 8.4187\n",
      "Epoch 32/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_2 Loss: 0.2889\n",
      "val mnist_test Loss: 0.0431\n",
      "val fashion Loss: 5.5588\n",
      "val kmnist Loss: 8.4183\n",
      "start_epoch_idx =  17\n",
      "valid_loss = 0.042841\n",
      "Epoch 18/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.5032\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9706\n",
      "val kmnist Loss: 8.6074\n",
      "Epoch 19/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.5021\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9535\n",
      "val kmnist Loss: 8.6003\n",
      "Epoch 20/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.5002\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9328\n",
      "val kmnist Loss: 8.5925\n",
      "Epoch 21/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4975\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.9086\n",
      "val kmnist Loss: 8.5839\n",
      "Epoch 22/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4939\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8685\n",
      "val kmnist Loss: 8.5676\n",
      "Epoch 23/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4891\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.8117\n",
      "val kmnist Loss: 8.5431\n",
      "Epoch 24/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4826\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.7543\n",
      "val kmnist Loss: 8.5177\n",
      "Epoch 25/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4758\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.7479\n",
      "val kmnist Loss: 8.5149\n",
      "Epoch 26/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4751\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.7400\n",
      "val kmnist Loss: 8.5114\n",
      "Epoch 27/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4742\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.7315\n",
      "val kmnist Loss: 8.5077\n",
      "Epoch 28/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4733\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7235\n",
      "val kmnist Loss: 8.5040\n",
      "Epoch 29/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4723\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7161\n",
      "val kmnist Loss: 8.5006\n",
      "Epoch 30/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4715\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7092\n",
      "val kmnist Loss: 8.4975\n",
      "Epoch 31/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4707\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7030\n",
      "val kmnist Loss: 8.4946\n",
      "Epoch 32/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_3 Loss: 0.4699\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7024\n",
      "val kmnist Loss: 8.4943\n",
      "start_epoch_idx =  17\n",
      "valid_loss = 0.042841\n",
      "Epoch 18/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4655\n",
      "val mnist_test Loss: 0.0428\n",
      "val fashion Loss: 5.9627\n",
      "val kmnist Loss: 8.6030\n",
      "Epoch 19/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4633\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.9239\n",
      "val kmnist Loss: 8.5845\n",
      "Epoch 20/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4590\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8775\n",
      "val kmnist Loss: 8.5626\n",
      "Epoch 21/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4533\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.8327\n",
      "val kmnist Loss: 8.5413\n",
      "Epoch 22/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4477\n",
      "val mnist_test Loss: 0.0426\n",
      "val fashion Loss: 5.7896\n",
      "val kmnist Loss: 8.5207\n",
      "Epoch 23/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4420\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7479\n",
      "val kmnist Loss: 8.5006\n",
      "Epoch 24/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4359\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.7038\n",
      "val kmnist Loss: 8.4789\n",
      "Epoch 25/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4292\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6990\n",
      "val kmnist Loss: 8.4765\n",
      "Epoch 26/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4285\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6938\n",
      "val kmnist Loss: 8.4738\n",
      "Epoch 27/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4278\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6882\n",
      "val kmnist Loss: 8.4711\n",
      "Epoch 28/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4270\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6830\n",
      "val kmnist Loss: 8.4685\n",
      "Epoch 29/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4262\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6781\n",
      "val kmnist Loss: 8.4661\n",
      "Epoch 30/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4255\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6734\n",
      "val kmnist Loss: 8.4638\n",
      "Epoch 31/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4249\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6689\n",
      "val kmnist Loss: 8.4615\n",
      "Epoch 32/32\n",
      "----------\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_4 Loss: 0.4242\n",
      "val mnist_test Loss: 0.0425\n",
      "val fashion Loss: 5.6684\n",
      "val kmnist Loss: 8.4612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Resume training on train set\n",
    "# phases = [('train','mnist_train'), ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "\n",
    "# Resume training on mixture\n",
    "# phases = [('train',\"mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100\"), \n",
    "#             ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "# phases = [('train',\"mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_1\"), \n",
    "#             ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "# phases = [('train',\"mixture_{'mnist_test': 1, 'fashion': 99}_scod_flagged_99_train_1\"), \n",
    "#             ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "\n",
    "for b in range(num_batches):\n",
    "    initialized_model, exp_lr_scheduler, sgd_optimizer, criterion, device = set_up_model(dataset_name)\n",
    "    load_model_path = \"./best_model/mnist/best_model.pt\"\n",
    "    model, optimizer, start_epoch_idx, valid_loss = load_ckp(load_model_path, initialized_model, sgd_optimizer)\n",
    "    print(\"start_epoch_idx = \", start_epoch_idx)\n",
    "    print(\"valid_loss = {:.6f}\".format(valid_loss))\n",
    "\n",
    "    start_epochs = start_epoch_idx\n",
    "    num_epochs = 15\n",
    "    scheduler = exp_lr_scheduler\n",
    "\n",
    "    # phases = [('train',\"mixture_{'mnist_test': 1, 'fashion': 99}_scod_flagged_99_train_1_batch_\"+str(b)), \n",
    "    #         ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "\n",
    "    phases = [('train',\"mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100_batch_\"+str(b)), \n",
    "            ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "\n",
    "    losses = {p[1]: np.zeros(num_epochs) for p in phases}\n",
    "\n",
    "    # Resume training\n",
    "    for epoch in range(start_epochs, start_epochs+num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, start_epochs+num_epochs))\n",
    "        print('-' * 10)\n",
    "        for phase in phases:\n",
    "            if phase[0] == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # batch loop\n",
    "            for d in dataloaders[phase[1]]:\n",
    "                if len(d) == 2:\n",
    "                    inputs, labels = d \n",
    "                elif len(d) == 3:\n",
    "                    inputs, labels, fnames = d \n",
    "                else:\n",
    "                    raise ValueError(\"Unrecognized. Dataloader entry has length {}\".format(len(d)))\n",
    "                labels = labels.flatten().type(torch.LongTensor)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase[0] == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase[0] == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase[1]]\n",
    "            print('{} {} Loss: {:.4f}'.format(phase[0], phase[1], epoch_loss))\n",
    "            if phase[0] == 'train':\n",
    "                scheduler.step()\n",
    "            losses[phase[1]][epoch-start_epochs] = epoch_loss\n",
    "\n",
    "    # Save train losses and valid losses\n",
    "    losses_path = \"./losses/\"\n",
    "    fname = \"ours_batch_\"+str(b)+\"_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") +'.npz' \n",
    "    with open(losses_path+fname, \"wb\") as fp:\n",
    "        pickle.dump(losses, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume training in a new way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_epoch_idx =  17\n",
      "valid_loss = 0.042841\n"
     ]
    }
   ],
   "source": [
    "initialized_model, exp_lr_scheduler, sgd_optimizer, criterion, device = set_up_model(dataset_name)\n",
    "load_model_path = \"./best_model/mnist/best_model.pt\"\n",
    "model, optimizer, start_epoch_idx, valid_loss = load_ckp(load_model_path, initialized_model, sgd_optimizer)\n",
    "print(\"start_epoch_idx = \", start_epoch_idx)\n",
    "print(\"valid_loss = {:.6f}\".format(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18\n",
      "----------\n",
      "Weight space dimension: 4.443e+04\n",
      "computing basis\n",
      "using T = 304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0529bc437f54782b711dce7bb35f3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty:  2.294168472290039\n",
      "LtJ shape is  (10, 44426)\n",
      "New Uncertainty:  2.294233798980713\n",
      "Trace is  0.0057763914\n",
      "Uncertainty:  2.2781007289886475\n",
      "LtJ shape is  (10, 44426)\n",
      "New Uncertainty:  2.2781505584716797\n",
      "Trace is  0.039836433\n",
      "Uncertainty:  2.2669413089752197\n",
      "LtJ shape is  (10, 44426)\n",
      "New Uncertainty:  2.266752243041992\n",
      "Trace is  -0.010459036\n",
      "Uncertainty:  2.258082151412964\n",
      "LtJ shape is  (10, 44426)\n",
      "New Uncertainty:  2.2576828002929688\n",
      "Trace is  0.052654635\n",
      "train mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100 Loss: 0.3520\n",
      "val mnist_test Loss: 0.0427\n",
      "val fashion Loss: 5.8917\n",
      "val kmnist Loss: 8.5776\n",
      "{\"mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100\": array([0.35199595]), 'mnist_test': array([0.04272059]), 'fashion': array([5.89165637]), 'kmnist': array([8.57758451])}\n"
     ]
    }
   ],
   "source": [
    "start_epochs = start_epoch_idx\n",
    "num_epochs = 1\n",
    "scheduler = exp_lr_scheduler\n",
    "\n",
    "# Resume training on train set\n",
    "# phases = [('train','mnist_train'), ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "\n",
    "# Resume training on mixture\n",
    "phases = [('train',\"mixture_{'mnist_test': 90, 'fashion': 10}_scod_flagged_10_train_100\"), \n",
    "            ('val','mnist_test'), ('val','fashion'), ('val','kmnist')]\n",
    "\n",
    "losses = {p[1]: np.zeros(num_epochs) for p in phases}\n",
    "\n",
    "dist_layer = scod.distributions.CategoricalLogitLayer()\n",
    "\n",
    "# Resume training\n",
    "for epoch in range(start_epochs, start_epochs+num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, start_epochs+num_epochs))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Create new unc model\n",
    "    new_unc_model = init_scod(model, dataloaders[\"mnist_train\"], dataset_name) \n",
    "\n",
    "    for phase in phases:\n",
    "        if phase[0] == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # batch loop\n",
    "        for d in dataloaders[phase[1]]:\n",
    "            if len(d) == 2:\n",
    "                inputs, labels = d \n",
    "            elif len(d) == 3:\n",
    "                inputs, labels, fnames = d \n",
    "            else:\n",
    "                raise ValueError(\"Unrecognized. Dataloader entry has length {}\".format(len(d)))\n",
    "            labels = labels.flatten().type(torch.LongTensor)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase[0] == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                \n",
    "\n",
    "                if phase[0] == 'train':\n",
    "                    for i in inputs[:2]:\n",
    "                        unc = eval_scod(i, unc_model, dist_layer)\n",
    "                        unc = unc.item()\n",
    "                        print(\"Uncertainty: \", unc)\n",
    "                        LtJ = get_Lt_J(i.unsqueeze(0), unc_model, debug=False, dist_layer=dist_layer)\n",
    "                        orig_trace = np.trace(LtJ)\n",
    "                        print(\"LtJ shape is \", np.shape(LtJ))\n",
    "\n",
    "                        new_unc = eval_scod(i, new_unc_model, dist_layer)\n",
    "                        new_unc = new_unc.item()\n",
    "                        print(\"New Uncertainty: \", new_unc)\n",
    "                        new_LtJ = get_Lt_J(i.unsqueeze(0), new_unc_model, debug=False, dist_layer=dist_layer)\n",
    "                        diff = np.trace(new_LtJ - LtJ)\n",
    "                        print(\"Trace is \", diff/orig_trace)\n",
    "\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / dataset_sizes[phase[1]]\n",
    "        print('{} {} Loss: {:.4f}'.format(phase[0], phase[1], epoch_loss))\n",
    "        if phase[0] == 'train':\n",
    "            scheduler.step()\n",
    "        losses[phase[1]][epoch-start_epochs] = epoch_loss\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mixture dataset using flagged inputs and weighting by uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test seq  0  algorithm  0  flagged:  [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, True, True, False, True, True, True]\n",
      "Uncertainty:  2.293386936187744\n",
      "Uncertainty:  2.296449899673462\n",
      "Uncertainty:  2.2916970252990723\n",
      "Uncertainty:  2.295175552368164\n",
      "Uncertainty:  2.2911081314086914\n",
      "Uncertainty:  2.2927355766296387\n",
      "Uncertainty:  2.294149398803711\n",
      "Uncertainty:  2.2983007431030273\n",
      "Uncertainty:  2.2959296703338623\n",
      "Uncertainty:  2.299753189086914\n"
     ]
    }
   ],
   "source": [
    "ood_ratio = 0.1\n",
    "mix_train_ratio = 1.0\n",
    "num_batches = 1\n",
    "\n",
    "ood_num = int(batch_size*ood_ratio)\n",
    "mix_train_num = int(batch_size*mix_train_ratio)\n",
    "\n",
    "batch_compositions = [  {'mnist_test':batch_size - ood_num,'fashion':ood_num}]\n",
    "train_batch_compositions = [{'mnist_train':mix_train_num}]\n",
    "\n",
    "flag_limit = ood_num\n",
    "# algs_to_test = [lambda x: scod_flagger(x, unc_model, flag_limit=flag_limit, debug = False, dist_layer = scod.distributions.CategoricalLogitLayer()), \n",
    "#                 lambda x: ds_scod_flagger(x, unc_model, flag_limit=flag_limit, dist_layer = scod.distributions.CategoricalLogitLayer())]\n",
    "algs_to_test = [lambda x: scod_flagger(x, unc_model, flag_limit=flag_limit, debug = False, dist_layer = scod.distributions.CategoricalLogitLayer())] \n",
    "algs_names = ['scod_flagged']\n",
    "\n",
    "flagged_inputs, flagged_labels, flagged_fnames, flags = alg_flags(algs_to_test, dataset_name, batch_size, num_batches, batch_compositions)\n",
    "train_inputs, train_labels, train_fnames = create_benchmark_seq_batches(dataset_name, mix_train_num, num_batches, train_batch_compositions)\n",
    "for k in range(len(algs_to_test)):\n",
    "    for i in range(num_batches):\n",
    "        flagged_subset = [(ts, lbl) for (ts,lbl,flg) in zip(flagged_inputs[i], flagged_labels[i], flags[i][k]) if flg]\n",
    "        train_subset = [(ts, lbl) for (ts,lbl) in zip(train_inputs[i], train_labels[i])]\n",
    "        \n",
    "        if unc_model is not None:\n",
    "            dist_layer = scod.distributions.CategoricalLogitLayer()\n",
    "            for fs in flagged_subset:\n",
    "                unc = eval_scod(fs[0] , unc_model, dist_layer)\n",
    "                unc = unc.item()\n",
    "                print(\"Uncertainty: \", unc)\n",
    "        \n",
    "        # refine_subset = flagged_subset + train_subset\n",
    "        # random.shuffle(refine_subset)\n",
    "\n",
    "        # mix_name = \"mixture_weighted\"+str(batch_compositions[i])+'_'+algs_names[k]+'_'+str(len(flagged_subset))+'_train_'+str(len(train_subset))\n",
    "        \n",
    "        # dataloaders[mix_name] = DataLoader(refine_subset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        # dataset_sizes[mix_name]  = len(refine_subset)\n",
    "        # print(\"Added \", mix_name, \" to list of dataloaders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
